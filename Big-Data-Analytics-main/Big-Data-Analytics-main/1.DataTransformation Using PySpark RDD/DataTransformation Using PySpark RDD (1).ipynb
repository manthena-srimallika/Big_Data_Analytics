{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74070f7-ad6c-4838-af7a-ca1e32c99a9c",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "\n",
    "Total Records: 50 students\n",
    "\n",
    "Columns: 7 → id, name, age, gender, math, science, english\n",
    "\n",
    "No missing values\n",
    "\n",
    "# Demographics\n",
    "\n",
    "Age: 18 – 25 years (average ≈ 21.5)\n",
    "\n",
    "Gender: 29 Female, 21 Male\n",
    "# Academic Performance\n",
    "\n",
    "# Math:\n",
    "Range: 40 – 100\n",
    "\n",
    "Mean: 68.9\n",
    "\n",
    "Std. Dev.: 17.6 (high variation)\n",
    "\n",
    "# Science:\n",
    "Range: 44 – 99\n",
    "\n",
    "Mean: 70.2\n",
    "\n",
    "Std. Dev.: 14.6 (moderate variation)\n",
    "\n",
    "# English:\n",
    "\n",
    "Range: 42 – 100\n",
    "\n",
    "Mean: 69.4\n",
    "\n",
    "Std. Dev.: 18.7 (highest variation)\n",
    "\n",
    "# Key Insights\n",
    "\n",
    "Science is the strongest subject on average.\n",
    "\n",
    "English has the most variation in performance.\n",
    "\n",
    "Students perform differently across subjects (not uniform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce856f6-5e95-469c-b098-fce37c9e072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://VARUN7777:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ac744-5714-443a-9a81-7c42eb7c126c",
   "metadata": {},
   "source": [
    "# Perform simple data transformation like filtering evennumbers from a given list using PySpark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4731ec0d-8759-4fa3-945c-130933facb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e495bc-fe89-4f55-8a8a-f18702d9e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original List:\n",
      "[63, 274, 908, 61, 985, 635, 493, 776, 99, 301, 27, 804, 484, 197, 886, 173, 41, 289, 815, 19, 550, 667, 122, 14, 485, 611, 862, 391, 787, 954, 315, 470, 197, 528, 569, 311, 599, 57, 107, 162, 994, 939, 245, 32, 551, 403, 506, 730, 439, 399, 616, 382, 286, 41, 778, 438, 338, 548, 56, 654, 891, 28, 906, 104, 638, 752, 910, 692, 298, 576, 222, 484, 224, 168, 347, 593, 784, 23, 199, 765, 285, 69, 506, 422, 855, 245, 244, 823, 920, 946, 362, 474, 707, 513, 944, 261, 818, 456, 766, 132]\n"
     ]
    }
   ],
   "source": [
    "random_numbers = [random.randint(1, 1000) for _ in range(100)]\n",
    "print(\"Original List:\")\n",
    "print(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f536ef69-3c24-4c55-8ede-640a8600d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_rdd = sc.parallelize(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d08f87b-c098-41e4-8b4a-74d4ae34fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_numbers_rdd = numbers_rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b2a058-8dde-4ad4-b653-e522be8007a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Even Numbers:\n",
      "[274, 908, 776, 804, 484, 886, 550, 122, 14, 862, 954, 470, 528, 162, 994, 32, 506, 730, 616, 382, 286, 778, 438, 338, 548, 56, 654, 28, 906, 104, 638, 752, 910, 692, 298, 576, 222, 484, 224, 168, 784, 506, 422, 244, 920, 946, 362, 474, 944, 818, 456, 766, 132]\n"
     ]
    }
   ],
   "source": [
    "even_numbers = even_numbers_rdd.collect()\n",
    "print(\"\\nEven Numbers:\")\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be55b4e-e4fa-4895-ae0b-5779783505b8",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Demonstrates data transformation using PySpark RDDs.\n",
    "\n",
    "Focuses on applying RDD operations (transformations & actions) for big data handling.\n",
    "\n",
    "Operations Performed\n",
    "\n",
    "# 1. Setup\n",
    "Imported PySpark libraries.\n",
    "\n",
    "Created a SparkContext to work with RDDs.\n",
    "\n",
    "Loaded sample data (possibly text/CSV).\n",
    "\n",
    "# 2. RDD Creation\n",
    "Data converted into RDD using sc.parallelize() or textFile().\n",
    "\n",
    "# 3. Transformations\n",
    "Operations that define a new RDD but do not execute immediately (lazy evaluation):\n",
    "\n",
    "map() → apply function to each element.\n",
    "\n",
    "filter() → filter elements based on condition.\n",
    "\n",
    "flatMap() → split elements into multiple parts.\n",
    "\n",
    "distinct() → remove duplicates.\n",
    "\n",
    "union() / intersection() → combine datasets.\n",
    "\n",
    "groupByKey() / reduceByKey() → group and aggregate.\n",
    "\n",
    "# 4. Actions\n",
    "Operations that trigger execution and return results:\n",
    "\n",
    "collect() → return all elements.\n",
    "\n",
    "count() → count records.\n",
    "\n",
    "first() → first element.\n",
    "\n",
    "take(n) → first n elements.\n",
    "\n",
    "reduce() → aggregate values.\n",
    "\n",
    "# 5. Data Transformation Examples\n",
    "Converting strings to key-value pairs.\n",
    "\n",
    "Filtering based on conditions (e.g., ages > 20).\n",
    "\n",
    "Aggregating numbers (sum, average, min, max).\n",
    "\n",
    "Word count (common beginner example).\n",
    "\n",
    "# 6. Output & Verification\n",
    "Displaying transformed data with .collect().\n",
    "\n",
    "Checking counts, sums, or sample records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
